{
 "metadata": {
  "name": "",
  "signature": "sha256:15cb65ce86370549acba3f20d2788dd68cf75114e0f9e3277e7481e53b2727c5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "GitHubArchive consumer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're going to use [GitHubArchive](http://www.githubarchive.com) to retrieve a lot of data from GitHub activity stream.\n",
      "GitHubArchive provides several file whose names are http://data.githubarchive.org/{year}-{month}-{day}-{hour}.json.gz that we are going to retrieve. GitHubArchive provides those files since 2011-12-02, but the file format has changed at the beginning of 2015.\n",
      "\n",
      "We first generate a list of links we are interested in, say from 2013-01-01 to 2013-01-05 excluded."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dateutil import rrule\n",
      "from datetime import date\n",
      "\n",
      "start_date = date(2013, 1, 1)\n",
      "end_date = date(2013, 1, 5)\n",
      "\n",
      "date_list = rrule.rrule(rrule.HOURLY, dtstart=start_date, until=end_date)\n",
      "\n",
      "link_format = 'http://data.githubarchive.org/{year}-{month:0>2}-{day:0>2}-{hour}.json.gz'\n",
      "\n",
      "links = [link_format.format(year=d.year, month=d.month, day=d.day, hour=d.hour) for d in date_list]\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    print '\\n'.join(links)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The easiest way to retrieve several files is using `wget` (or `requests` module in Python). Assuming you stored the list of links in a file *links.txt*: \n",
      "```\n",
      "wget -i links.txt -nc -c\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Those files are mainly JSON strings that are gzipped. It is easy to get its content using the following function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import gzip\n",
      "\n",
      "def get_content_from_file(filepath):\n",
      "    \"\"\"\n",
      "    Return a list of JSON structures that are contained in the file\n",
      "    described by filepath. This function expects that the file is \n",
      "    gzipped.\n",
      "    \"\"\"\n",
      "    \n",
      "    with gzip.GzipFile(filepath) as f:\n",
      "        content = map(json.loads, f.readlines())\n",
      "    return content\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Say we are interested to get the content of every file that we downloaded:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "# Assuming we are inside the right directory and there is no other files in it.\n",
      "filename_list = os.listdir('.')  \n",
      "\n",
      "# 'activity' will store the entire activity stream\n",
      "activity = []\n",
      "for filename in filename_list: \n",
      "    activity += get_content_from_file(filename)\n",
      "    \n",
      "# Now, activity contains the entiere activity stream\n",
      "print activity[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}