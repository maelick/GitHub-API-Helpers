{
 "metadata": {
  "name": "",
  "signature": "sha256:9ce6699c4dc95b100e21c7daa00d802a9e4e48bde96c7b9e4d12c43dcbcfcfea"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Github Repositories and R Packages"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dans nos diff\u00e9rents jeux de donn\u00e9es, nous avons pour l'instant : \n",
      " - Une liste des d\u00e9p\u00f4ts li\u00e9s \u00e0 R qui sont encore actifs en date du 17 f\u00e9vrier 2015. Ces d\u00e9p\u00f4ts ont \u00e9t\u00e9 identifi\u00e9s sur base des \u00e9v\u00e9nements de type \"PushEvent\" qui se sont produits entre 2013 et 2014 (inclus).\n",
      " - Une liste des d\u00e9p\u00f4ts contenant un fichier `DESCRIPTION` \u00e0 la racine du d\u00e9p\u00f4t, ainsi que le contenu de ce fichier. Cela nous permet d'avoir une liste des paquets qui sont d\u00e9velopp\u00e9s et/ou h\u00e9berg\u00e9s sur GitHub. Les fichiers ont \u00e9t\u00e9 collect\u00e9s le 17 f\u00e9vrier 2015. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ces donn\u00e9es nous permettent d\u00e9j\u00e0 d'obtenir beaucoup d'informations sur ce qui se passe sur Github pour les paquets R. N\u00e9anmoins, nous n'avons pas encore filtr\u00e9 les forks. En supprimant les forks, nous \u00e9viterons d'obtenir un m\u00eame package R depuis plusieurs d\u00e9p\u00f4ts Github. Cela permettra d'avoir les informations du fichier `DESCRIPTION` depuis ce qui est probablement le d\u00e9p\u00f4t principal, que nous esp\u00e9rons \u00eatre le d\u00e9p\u00f4t de d\u00e9veloppement de ce package. \n",
      "\n",
      "Afin d'identifier quels sont les d\u00e9p\u00f4ts qui sont ou non des forks, il va falloir retravailler avec notre base MongoDB."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymongo\n",
      "import pandas\n",
      "\n",
      "conn = pymongo.MongoClient()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notre collection \"events\" dans \"R\" contient tous les \u00e9v\u00e9nements de 2013 et 2014. Nous allons filtrer les PushEvents, et r\u00e9cup\u00e9rer les d\u00e9p\u00f4ts associ\u00e9s. Ensuite, nous associerons un flag \"fork\" pour indiquer si ce d\u00e9p\u00f4t est un fork ou pas. L'objectif \u00e9tant de recouper ces informations avec celles que nous poss\u00e9dons d\u00e9j\u00e0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = []\n",
      "\n",
      "query = {'type': 'PushEvent', 'repository': {'$exists': True}}\n",
      "project = ['repository.owner', 'repository.name', 'repository.url', 'repository.created_at', 'repository.pushed_at', 'repository.fork', 'repository.forks']\n",
      "for item in conn.r.events.find(query, project):\n",
      "    rows.append(item)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cela peut prendre un peu de temps vu le nombre d'\u00e9l\u00e9ments \u00e0 devoir traiter. Afin de pouvoir travailler avec les r\u00e9sultats, il convient d'adapter quelque peu la structure de donn\u00e9es que nous avons r\u00e9cup\u00e9r\u00e9e :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(rows), rows[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(683425,\n",
        " [{u'_id': ObjectId('54ec348ec9896e203c522fd4'),\n",
        "   u'repository': {u'created_at': u'2011-03-23T16:40:49-07:00',\n",
        "    u'fork': False,\n",
        "    u'forks': 0,\n",
        "    u'name': u'Papers',\n",
        "    u'owner': u'ntustison',\n",
        "    u'pushed_at': u'2013-05-26T07:08:21-07:00',\n",
        "    u'url': u'https://github.com/ntustison/Papers'}},\n",
        "  {u'_id': ObjectId('54ec348ec9896e2035522fd4'),\n",
        "   u'repository': {u'created_at': u'2013-02-28T07:18:32-08:00',\n",
        "    u'fork': False,\n",
        "    u'forks': 0,\n",
        "    u'name': u'lg',\n",
        "    u'owner': u'lionup',\n",
        "    u'pushed_at': u'2013-03-09T01:05:43-08:00',\n",
        "    u'url': u'https://github.com/lionup/lg'}}])"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Id\u00e9alement, nous voudrions : \n",
      "1. Supprimer les doublons pour le m\u00eame *owner* et le m\u00eame *repository*. \n",
      "2. R\u00e9cup\u00e9rer la valeur du *fork* la plus r\u00e9cente. \n",
      "3. *Flatteniser* les donn\u00e9es tout en conservant la date de cr\u00e9ation, et id\u00e9alement, la derni\u00e8re date connue d'\u00e9v\u00e9nement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _flatten(row): \n",
      "    repository = row['repository']\n",
      "    created_at = repository['created_at']\n",
      "    owner = repository['owner']\n",
      "    name = repository['name']\n",
      "    url = repository['url']\n",
      "    pushevent = repository['pushed_at']\n",
      "    fork = repository['fork']\n",
      "    forks = repository['forks']\n",
      "    return {'owner': owner, 'repository': name, 'creation': created_at, 'last_push': pushevent, 'fork': fork, 'forks': forks}\n",
      "\n",
      "df = pandas.DataFrame.from_dict(map(_flatten, rows))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nous avons maintenant un joli tableau sur lequel il nous reste \u00e0 supprimer les doublons et conserver la valeur la plus r\u00e9cente, pour chaque (owner, repository). Pandas va nous aider, avec `drop_duplicates`..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "repos = df.drop_duplicates(('owner', 'repository'), take_last=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "repos.to_csv('../data/R-Repositories.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nous avons pr\u00e9c\u00e9demment identifier, pour chaque d\u00e9p\u00f4t, lesquels \u00e9taient associ\u00e9s \u00e0 un package R. Les donn\u00e9es sont situ\u00e9es dans le fichier `github-description.csv`. Ce fichier contient, pour chaque couple (owner, repository) une liste des cl\u00e9s/valeurs du fichier `DESCRIPTION`. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "descriptions = pandas.DataFrame.from_csv('../data/github-description.csv', index_col=None)\n",
      "packages = descriptions.query('key == \"Package\"').rename(columns={'value': 'Package'})[['owner', 'repository', 'Package']]\n",
      "authors = descriptions.query('key == \"Author\"').rename(columns={'value': 'Author'})[['owner', 'repository', 'Author']]\n",
      "imports = descriptions.query('key == \"Imports\"').rename(columns={'value': 'Imports'})[['owner', 'repository', 'Imports']]\n",
      "depends = descriptions.query('key == \"Depends\"').rename(columns={'value': 'Depends'})[['owner', 'repository', 'Depends']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = packages.merge(repos, how='left', on=('owner', 'repository'))\n",
      "_ = _.merge(authors, how='left', on=('owner', 'repository'))\n",
      "_ = _.merge(imports, how='left', on=('owner', 'repository'))\n",
      "df = _.merge(depends, how='left', on=('owner', 'repository'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Certaines informations pr\u00e9sentes dans le fichier `github-description.csv` semblent ne pas exister dans notre collection d'\u00e9v\u00e9nements, probablement (\u00e0 confirmer) parce que ce fichier a \u00e9t\u00e9 cr\u00e9\u00e9 sur base de tous les \u00e9v\u00e9nements, pas seulements des *PushEvent*. Nous allons supprimer les \u00e9l\u00e9ments pour lesquels nous n'avons pas une telle information."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.dropna(axis=0, subset=('creation',))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Enfin, nous pouvons choisir __arbitrairement__ de ne consid\u00e9rer que les d\u00e9p\u00f4ts qui ne sont __pas__ des forks, et pour chaque package apparaissant dans au moins deux d\u00e9p\u00f4ts, de ne garder que le d\u00e9p\u00f4t avec la __date de cr\u00e9ation la plus ancienne__. L'\u00e9tiquette `canonical` est ajout\u00e9 sur chaque d\u00e9p\u00f4t ainsi identifi\u00e9. Avant de faire cette op\u00e9ration, nous allons retirer les packages associ\u00e9s \u00e0 `cran` et `rpkg` (owners sur Github) car il s'agit d'un mirroring, et donc clairement pas de d\u00e9p\u00f4ts de d\u00e9veloppement. Notez que ces d\u00e9p\u00f4ts seront encore pr\u00e9sents dans le .csv final, mais ils ne seront simplement pas pris en compte pour l'ajout de l'\u00e9tiquette `canonical`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = df.query('fork == False and owner != \"cran\" and owner != \"rpkg\"')\n",
      "_ = _.sort(columns='creation')\n",
      "_ = _.drop_duplicates('Package')\n",
      "_['canonical'] = 1\n",
      "df = df.merge(_[['owner', 'repository', 'canonical']], how='left', on=('owner', 'repository'))\n",
      "df = df.fillna(value={'canonical': 0, 'Author': '', 'Imports': '', 'Depends': ''})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv('../data/github-RPackage-repository.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}